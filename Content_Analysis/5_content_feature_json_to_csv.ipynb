{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764},"executionInfo":{"elapsed":16702,"status":"ok","timestamp":1651079413995,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"},"user_tz":240},"id":"Gj0x_JrWeDJu","outputId":"c210b102-9ffa-4253-a847-2dc1b2d2174d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting google-cloud-videointelligence\n","  Downloading google_cloud_videointelligence-2.6.1-py2.py3-none-any.whl (202 kB)\n","\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 92 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 202 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-videointelligence) (1.31.5)\n","Collecting proto-plus>=1.15.0\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (21.3)\n","Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (1.35.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (1.56.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (2022.1)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (2.23.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (1.15.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (57.4.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (3.17.3)\n","Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (1.44.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (0.2.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (3.0.8)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 32.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-videointelligence) (3.0.4)\n","Installing collected packages: protobuf, proto-plus, google-cloud-videointelligence\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n","Successfully installed google-cloud-videointelligence-2.6.1 proto-plus-1.20.3 protobuf-3.20.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}}],"source":["!pip3 install --upgrade google-cloud-videointelligence"]},{"cell_type":"code","source":[""],"metadata":{"id":"-aNaXpA1rAya"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6wtmVNMRjcH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079551117,"user_tz":240,"elapsed":3196,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"1abf1633-094d-4fd2-9d61-e4920006ae84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\", force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"hZSmxPudo_6z"},"source":["Make a copy of 'Systems '22' at your own **MyDrive** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SUjcaOdVdR8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079551118,"user_tz":240,"elapsed":12,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"b9eee5b0-fbb3-49ef-9c11-db57902a40c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1ohwBGdC8wri16R_SjnGnOM_B619TDepK/Systems '22\n"]}],"source":["%cd gdrive/MyDrive/\"Systems '22\"/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvqsdhfwX3kZ"},"outputs":[],"source":["import sys\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6r_oey-hYFWG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e3cd60f-1dea-473a-a692-883b03a71c06","executionInfo":{"status":"ok","timestamp":1651079576262,"user_tz":240,"elapsed":24650,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["API [cloudbilling.googleapis.com] not enabled on project [522309567947]. Would \n","you like to enable and retry (this will take a few minutes)? (y/N)?  y\n","\n","Enabling service [cloudbilling.googleapis.com] on project [522309567947]...\n","\u001b[1;31mERROR:\u001b[0m (gcloud.beta.billing.projects.link) PERMISSION_DENIED: Permission denied to enable service [cloudbilling.googleapis.com]\n","Help Token: Ae-hA1MQIU1vJ1O7evF1rGsPZLmJDh1ST96QJydHIUbyOj3zfNwcTzmODNEpI69gWZFilZ2LSTwNjWDKoHRSbdMD1vw9zDjRCaAPIdWsOv9VI1k_\n","- '@type': type.googleapis.com/google.rpc.PreconditionFailure\n","  violations:\n","  - subject: '110002'\n","    type: googleapis.com\n","- '@type': type.googleapis.com/google.rpc.ErrorInfo\n","  domain: serviceusage.googleapis.com\n","  reason: AUTH_PERMISSION_DENIED\n"]}],"source":["BILLING_ACCOUNT_ID = '01074B-EAE851-71F16B7'\n","\n","GCP_PROJECT_ID = 'stoked-dominion-341317'\n","PROJECT_NUMBER = '725342657078'\n","\n","!gcloud beta billing projects link $GCP_PROJECT_ID --billing-account $BILLING_ACCOUNT_ID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gnpJ6cjYCuJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079588673,"user_tz":240,"elapsed":12419,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"8a1b6580-2247-4cb6-bc41-8793e68f5205"},"outputs":[{"output_type":"stream","name":"stdout","text":["API [cloudbilling.googleapis.com] not enabled on project [522309567947]. Would \n","you like to enable and retry (this will take a few minutes)? (y/N)?  y\n","\n","Enabling service [cloudbilling.googleapis.com] on project [522309567947]...\n","\u001b[1;31mERROR:\u001b[0m (gcloud.beta.billing.accounts.list) PERMISSION_DENIED: Permission denied to enable service [cloudbilling.googleapis.com]\n","Help Token: Ae-hA1OfPnqieFtMLoXt4UDvIhWbq-HRdtpjx4fQ2YyRPcExoLmiWS8ouGViQANjuIwxc1u18o7MwkTTGiiRQQu6ewl6j2sKN3nZOwHmNZbm18oq\n","- '@type': type.googleapis.com/google.rpc.PreconditionFailure\n","  violations:\n","  - subject: '110002'\n","    type: googleapis.com\n","- '@type': type.googleapis.com/google.rpc.ErrorInfo\n","  domain: serviceusage.googleapis.com\n","  reason: AUTH_PERMISSION_DENIED\n"]}],"source":["!gcloud beta billing accounts list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xWdNOQgZVzq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079594190,"user_tz":240,"elapsed":5523,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"b51fd4a2-4350-40fc-d683-9d3eb312f355"},"outputs":[{"output_type":"stream","name":"stdout","text":["Operation \"operations/acat.p2-725342657078-a92e9286-3860-47ca-90cf-dc04cb2fe837\" finished successfully.\n"]}],"source":["!gcloud services --project $GCP_PROJECT_ID enable ml.googleapis.com cloudbuild.googleapis.com"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okzN6ojiZqo_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079597358,"user_tz":240,"elapsed":3188,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"5759b54a-b5b6-497e-fcf0-8c72257d440c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated IAM policy for project [stoked-dominion-341317].\n","bindings:\n","- members:\n","  - user:ylingqin08@gmail.com\n","  role: roles/billing.projectManager\n","- members:\n","  - serviceAccount:725342657078@cloudbuild.gserviceaccount.com\n","  role: roles/cloudbuild.builds.builder\n","- members:\n","  - serviceAccount:service-725342657078@gcp-sa-cloudbuild.iam.gserviceaccount.com\n","  role: roles/cloudbuild.serviceAgent\n","- members:\n","  - serviceAccount:service-725342657078@gcf-admin-robot.iam.gserviceaccount.com\n","  role: roles/cloudfunctions.serviceAgent\n","- members:\n","  - serviceAccount:service-725342657078@cloudcomposer-accounts.iam.gserviceaccount.com\n","  role: roles/composer.serviceAgent\n","- members:\n","  - serviceAccount:service-725342657078@compute-system.iam.gserviceaccount.com\n","  role: roles/compute.serviceAgent\n","- members:\n","  - serviceAccount:service-725342657078@container-engine-robot.iam.gserviceaccount.com\n","  role: roles/container.serviceAgent\n","- members:\n","  - serviceAccount:service-725342657078@containerregistry.iam.gserviceaccount.com\n","  role: roles/containerregistry.ServiceAgent\n","- members:\n","  - serviceAccount:725342657078-compute@developer.gserviceaccount.com\n","  - serviceAccount:725342657078@cloudservices.gserviceaccount.com\n","  - serviceAccount:ytanalytics@stoked-dominion-341317.iam.gserviceaccount.com\n","  - serviceAccount:ytnotebook@stoked-dominion-341317.iam.gserviceaccount.com\n","  role: roles/editor\n","- members:\n","  - serviceAccount:service-725342657078@cloud-ml.google.com.iam.gserviceaccount.com\n","  role: roles/ml.serviceAgent\n","- members:\n","  - serviceAccount:speech2txt@stoked-dominion-341317.iam.gserviceaccount.com\n","  - serviceAccount:stoked-dominion-341317@appspot.gserviceaccount.com\n","  - serviceAccount:ytanalytics@stoked-dominion-341317.iam.gserviceaccount.com\n","  - user:atan230879@gmail.com\n","  - user:manzoormirza94@gmail.com\n","  - user:mharrismansur@gmail.com\n","  - user:sagokhal@andrew.cmu.edu\n","  - user:shraddhag995@gmail.com\n","  - user:yanglq08@gmail.com\n","  - user:yaxint@andrew.cmu.edu\n","  - user:ylingqin08@gmail.com\n","  role: roles/owner\n","- members:\n","  - serviceAccount:service-725342657078@gcp-sa-pubsub.iam.gserviceaccount.com\n","  role: roles/pubsub.serviceAgent\n","- members:\n","  - user:ylingqin@andrew.cmu.edu\n","  role: roles/resourcemanager.projectOwnerInvitee\n","- members:\n","  - serviceAccount:datacollection@stoked-dominion-341317.iam.gserviceaccount.com\n","  - serviceAccount:stoked-dominion-341317@appspot.gserviceaccount.com\n","  - user:manzoormirza94@gmail.com\n","  - user:mharrismansur@gmail.com\n","  role: roles/storage.objectCreator\n","etag: BwXdpeze0uw=\n","version: 1\n"]}],"source":["SERVICE_ACCOUNT_NAME ='ytnotebook'\n","\n","SERVICE_ACCOUNT_EMAIL = f'{SERVICE_ACCOUNT_NAME}@{GCP_PROJECT_ID}.iam.gserviceaccount.com'\n","#!gcloud iam --project $GCP_PROJECT_ID service-accounts create $SERVICE_ACCOUNT_NAME\n","!gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \\\n","    --member serviceAccount:$SERVICE_ACCOUNT_EMAIL \\\n","    --role=roles/editor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ndVBU1DaSWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079605835,"user_tz":240,"elapsed":8485,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"8c7bb9b6-25ce-49d6-f541-5e6d5dea75e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["API [iam.googleapis.com] not enabled on project [522309567947]. Would you like \n","to enable and retry (this will take a few minutes)? (y/N)?  y\n","\n","Enabling service [iam.googleapis.com] on project [522309567947]...\n","\u001b[1;31mERROR:\u001b[0m (gcloud.iam.service-accounts.add-iam-policy-binding) PERMISSION_DENIED: Permission denied to enable service [iam.googleapis.com]\n","Help Token: Ae-hA1P0OMy654oi2Bv-hOZDKQ2uXlBnPAv3eohl1hgMHIXR4SsdDeBQdKeEMyzyLDgsPiWBQJiijB97QP4o75uzLNCKhGPBl6ULVo5iitljmV1A\n","- '@type': type.googleapis.com/google.rpc.PreconditionFailure\n","  violations:\n","  - subject: '110002'\n","    type: googleapis.com\n","- '@type': type.googleapis.com/google.rpc.ErrorInfo\n","  domain: serviceusage.googleapis.com\n","  reason: AUTH_PERMISSION_DENIED\n"]}],"source":["DEFAULT_AI_PLATFORM_SERVICE_ACCOUNT = f'service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com'\n","\n","!gcloud iam --project $GCP_PROJECT_ID service-accounts add-iam-policy-binding \\\n","--role=roles/iam.serviceAccountAdmin \\\n","--member=serviceAccount:$DEFAULT_AI_PLATFORM_SERVICE_ACCOUNT \\\n","$SERVICE_ACCOUNT_EMAIL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTWMTYyndU__"},"outputs":[],"source":["import os, io\n","import pandas as pd\n","from google.cloud import videointelligence\n","from collections import namedtuple\n","import plotly.graph_objects as go\n","import plotly.express as px\n","import requests\n","import string\n","import proto\n","import json\n","\n","## download your API Key from your Google Console\n","\n","#this is the path to the API credentials. Modify this path to the json file in this folder.\n","os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'Scripts/stoked-dominion-341317-24484c3fbb6f.json'\n","video_client = videointelligence.VideoIntelligenceServiceClient()\n","\n","\n","import difflib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cn0cK6qyd3-X"},"outputs":[],"source":["from google.cloud import storage\n","\n","\n","video_list = []\n","def list_blobs_with_prefix(bucket_name, prefix, delimiter=None):\n","\n","    storage_client = storage.Client()\n","\n","    blobs = storage_client.list_blobs(bucket_name, prefix=prefix, delimiter=delimiter)\n","\n","    #print(\"Blobs:\")\n","    for blob in blobs:\n","      #print(blob.name)\n","      video_list.append(blob.name)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZS_DQZQYeHE"},"outputs":[],"source":["list_blobs_with_prefix(\n","        bucket_name=\"videos_final\", prefix=\"\", delimiter=\"/\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbBFVY0Ahw3c"},"outputs":[],"source":["def list_blobs_with_prefix1(bucket_name, prefix, out_list, delimiter=None):\n","    storage_client = storage.Client()\n","    blobs = storage_client.list_blobs(bucket_name, prefix=prefix, delimiter=delimiter)\n","\n","    #print(\"Blobs:\")\n","    for blob in blobs:\n","      #print(blob.name)\n","      out_list.append(blob.name)"]},{"cell_type":"markdown","metadata":{"id":"QxypJZuxJKNv"},"source":["### **Features Extraction**\n","\n","1. speech transcription (optional) \n","\n","2. shot change detection\n","\n","3. object detection\n","\n","4. OCR text detection"]},{"cell_type":"markdown","metadata":{"id":"Nw90pGlnljY7"},"source":["### Get all output files under 'outputXXX/' folder in GCP\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tpsg6o7mgX06","colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"status":"error","timestamp":1651079608483,"user_tz":240,"elapsed":746,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"4dafc31e-9c89-4baf-ce91-c4d967c3e67f"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-5aaf2d7ebf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabeled_vid_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabeled_vid_tab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labeled_video_content.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_vid_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlabeled_vid_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_vid_tab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'labeled_video_content.csv'"]}],"source":["labeled_vid_table={}\n","labeled_vid_tab=pd.read_csv('labeled_video_content.csv')\n","for i,v in enumerate(list(labeled_vid_tab['video_ID'])):\n","  labeled_vid_table[v]={}\n","  for q in labeled_vid_tab.columns[1:]:\n","    labeled_vid_table[v][q]=labeled_vid_tab.loc[i][q]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAsMtIEvtq4M"},"outputs":[],"source":["outputSpeech=[]\n","list_blobs_with_prefix1(bucket_name=\"video_list_capstoneyt_2022\", prefix=\"outputSpeech/\", delimiter=\"/\",out_list=outputSpeech)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lsa3iV7wiNju"},"outputs":[],"source":["outputDetection=[]      \n","list_blobs_with_prefix1(bucket_name=\"video_list_capstoneyt_2022\", prefix=\"outputDetection/\", delimiter=\"/\",out_list=outputDetection)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4OLhwzMl4va"},"outputs":[],"source":["outputOCR=[]\n","list_blobs_with_prefix1(bucket_name=\"video_list_capstoneyt_2022\", prefix=\"outputOCR/\", delimiter=\"/\",out_list=outputOCR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EpO9CCFJDWmQ"},"outputs":[],"source":["len(outputDetection)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xShH33ere0n_"},"outputs":[],"source":["outputLabeled=[]\n","list_blobs_with_prefix1(bucket_name=\"video_list_capstoneyt_2022\", prefix=\"outputLabeled/\", delimiter=\"/\", out_list=outputLabeled)"]},{"cell_type":"markdown","source":["###**Check duplicates** \n","\n"],"metadata":{"id":"TeiPqr8FpGPd"}},{"cell_type":"code","source":["print(len(outputLabeled))"],"metadata":{"id":"T0OclorSpFp2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(outputDetection))\n","print(len(outputSpeech))\n","print(len(outputOCR))"],"metadata":{"id":"UcVqzu1nvRMr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detectionIDs=[]\n","for o in outputDetection:\n","  detectionIDs.append(o[16:-5])"],"metadata":{"id":"H7Thsg4fvRVQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labeledIDs=[]\n","duplicates=0\n","for o in outputLabeled:\n","  labeledIDs.append(o[14:-9])\n","\n","print(len(labeledIDs))"],"metadata":{"id":"e7g14cJwwBF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0iY6MH8h51o"},"source":["\n","### **Feature to CSV**\n","1. Speech\n","\n","2. Scene detection/Object detection\n","\n","3. OCR texts "]},{"cell_type":"markdown","metadata":{"id":"1OAqxRoOyQbk"},"source":["**Speech**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YST6K8GnaaOU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651079670373,"user_tz":240,"elapsed":3767,"user":{"displayName":"Yaxin Tan","userId":"06040713991977481111"}},"outputId":"d17109e3-141f-45f7-81a3-56fd44374d1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}],"source":["import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import nltk\n","from nltk import pos_tag\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","\n","\n","#transition words and summary words\n","transition='Accordingly, as a result, and so, because, consequently, for that reason, hence, on account of, since, \\\n","    therefore, thus, after, afterwards, always, at length, during, earlier, following, immediately, in the meantime, later, \\\n","    never, next, once, simultaneously, so far, sometimes, soon, subsequently, then, this time, until now, when, whenever, while, \\\n","    additionally, again, also, and, or, not, besides, even more, finally, first, firstly, further, furthermore, in addition, \\\n","    in the first place, in the second place, last, lastly, moreover, next, second, secondly, after all, although, and yet, \\\n","    at the same time, but, despite, however, in contrast, nevertheless, notwithstanding, on the contrary, on the other hand, \\\n","    otherwise, thought, yet, as an illustration, e.g., for example, for instance, specifically, to demonstrate, to illustrate, \\\n","    briefly, critically, foundationally, more importantly, of less importance, primarily, above, centrally, opposite to, \\\n","    adjacent to, below, peripherally, below, nearby, beyond, in similar fashion, in the same way, likewise, in like manner, \\\n","    i.e., in other word, that is, to clarify, to explain, in fact, of course, undoubtedly, without doubt, surely, indeed, \\\n","    for this purpose, so that, to this end, in order that, to that end'.split(', ')\n","\n","\n","summary=['finally', 'in a word', 'in brief', 'briefly', \n","             'in conclusion', 'in the end', 'in the final analysis', 'on the whole', 'thus', 'to conclude', 'to summarize', \n","             'in sum', 'to sum up', 'in summary','lastly']\n","             \n","transition=[word.strip(' ') for word in transition]\n","\n","\n","\n","pos_tags='VB, VBD, VBG, VBP, VBZ'.split(', ')"]},{"cell_type":"markdown","metadata":{"id":"w1AS7ylHyCk2"},"source":["helper functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCR0f9oOx9CI"},"outputs":[],"source":["#return tags from words (ordered)\n","def tags_from_corpus(words):\n","  tag = nltk.pos_tag(words)\n","  #print(tag)\n","  tags=[t[1] for t in tag]\n","  return tags\n","   \n","\n","#count the number of occurrences of the words in word_list in corpus_list\n","def occurrences(corpus_list,word_list):\n","  res=0\n","  for t in corpus_list:\n","    if t in word_list:\n","      res+=1\n","  return res "]},{"cell_type":"markdown","metadata":{"id":"ixvyVVWNgR8V"},"source":["Speech for the already labeled vidoes (json file uploaded by Xiao)"]},{"cell_type":"code","source":["labeled_vid_table={}\n","corpuses={}\n","storage_client = storage.Client()\n","bucket = storage_client.get_bucket('video_list_capstoneyt_2022')"],"metadata":{"id":"ayTcotnQxPwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%ls"],"metadata":{"id":"zvqKwtMXAvL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install readability"],"metadata":{"id":"M3gjyU3tW-JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgmhL0-Lggiy"},"outputs":[],"source":["import readability\n","\n","for vid in outputLabeled:\n","  # get bucket data as blob\n","  blob = bucket.blob(vid)\n","  vid_file=vid[14:-5]\n","  vid_id=vid[14:-9]\n","  try:\n","    labeled_vid_table[vid_id]['transcript_sentence_count']+=0\n","  except:\n","    print('===========================================================\\nVideo: %s'%vid)\n","    #downloaded_blob = blob.download_as_string()\n","    #downloaded_blob = downloaded_blob.decode(\"utf-8\") \n","    # parse x:\n","    #y = json.loads(downloaded_blob)\n","    y1=open('Labeled GCP Output (Xiao)/'+vid_file+'.json')\n","    y=json.load(y1)\n","    labeled_vid_table[vid_id]={}\n","    #audio transcription \n","    try:\n","      try:\n","        atn=y[vid_file][0]['speech']['annotationResults'][0]['speechTranscriptions']\n","      except:\n","        try:\n","          atn=y['annotation_results'][0]['speech_transcriptions']\n","        except:\n","          atn=y['annotation_results'][1]['speech_transcriptions']\n","\n","      \n","\n","      corpus=\"\"\n","      #frequencies of word\n","      screen_time={}\n","      #confidence score of that entity \n","      conf=[]\n","\n","      for i in range(len(atn)):\n","        if 'transcript' in atn[i]['alternatives'][0].keys() and 'confidence' in atn[i]['alternatives'][0].keys():\n","          corpus+=(atn[i]['alternatives'][0]['transcript']+\"\\n\")\n","          conf.append(atn[i]['alternatives'][0]['confidence'])\n","      labeled_vid_table[vid_id]['transcript_sentence_count']=len(corpus.split('.'))\n","      labeled_vid_table[vid_id]['transcription_confidence_avg']=np.mean(conf)\n","      \n","      try:\n","        results = readability.getmeasures(corpus, lang='en')\n","        labeled_vid_table[vid_id]['readability']= results['readability grades']['ARI']\n","      except:\n","        print('readability unavailable!')\n","\n","      #word counts\n","      words=nltk.word_tokenize(corpus)\n","      corpuses[vid_id]=corpus\n","\n","      labeled_vid_table[vid_id]['transcript_wordcount']=len(words)\n","      labeled_vid_table[vid_id]['transcript_unique_wordcount']=len(set(words))  \n","\n","      labeled_vid_table[vid_id]['transcription_active_wordcount']=occurrences(tags_from_corpus(words),pos_tags)\n","      labeled_vid_table[vid_id]['transcription_summary_wordcount']=occurrences(words,summary)\n","      labeled_vid_table[vid_id]['transcription_transition_wordcount']=occurrences(words,transition)\n","      #https://py-readability-metrics.readthedocs.io/en/latest/\n","\n","      print('transcript features added.')\n","\n","    except:\n","      print('speech annotation does not exist!')"]},{"cell_type":"code","source":["for c in list(corpuses.keys()):\n","  with open('text/transcript_text/labeled/raw_text/%s.txt'%c,'w') as f:\n","    f.write(corpuses[c])"],"metadata":{"id":"qcA-RBrH1dUE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4zlTp1R9gLcp"},"source":["For the speech processing of our **new videos**"]},{"cell_type":"code","source":["corpuses_unlabeled={}\n","vid_table={}"],"metadata":{"id":"X4bjR9Up8r1h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCH01PPhkuQI"},"outputs":[],"source":["import readability\n","\n","for vid in outputSpeech:\n","  # get bucket data as blob\n","  blob = bucket.blob(vid)\n","  vid_id=vid[13:-5]\n","  try:\n","    vid_table[vid_id]['transcript_sentence_count']+=0\n","  except:\n","    print('===========================================================\\nVideo: %s'%vid)\n","    downloaded_blob = blob.download_as_string()\n","    downloaded_blob = downloaded_blob.decode(\"utf-8\") \n","    # parse x:\n","    y = json.loads(downloaded_blob)\n","    if vid_id not in vid_table.keys():\n","      vid_table[vid_id]={}\n","    #audio transcription \n","    if True:\n","    #try:\n","      atn=y['annotation_results'][0]['speech_transcriptions']\n","\n","      corpus=\"\"\n","      #frequencies of word\n","      screen_time={}\n","      #confidence score of that entity \n","      conf=[]\n","\n","      for i in range(len(atn)):\n","        if 'transcript' in atn[i]['alternatives'][0].keys(): \n","          corpus+=(atn[i]['alternatives'][0]['transcript']+\"\\n\")\n","        if 'confidence' in atn[i]['alternatives'][0].keys():\n","          conf.append(atn[i]['alternatives'][0]['confidence'])\n","      vid_table[vid_id]['transcript_sentence_count']=len(corpus.split('.'))\n","      vid_table[vid_id]['transcription_confidence_avg']=np.mean(conf)\n","      try:\n","        results = readability.getmeasures(corpus, lang='en')\n","        vid_table[vid_id]['readability']= results['readability grades']['ARI']\n","      except:\n","        print('readability unavailable!')\n","\n","      #word counts\n","      words=nltk.word_tokenize(corpus)\n","      corpuses_unlabeled[vid_id]=corpus\n","\n","      vid_table[vid_id]['transcript_wordcount']=len(words)\n","      vid_table[vid_id]['transcript_unique_wordcount']=len(set(words))  \n","\n","      vid_table[vid_id]['transcription_active_wordcount']=occurrences(tags_from_corpus(words),pos_tags)\n","      vid_table[vid_id]['transcription_summary_wordcount']=occurrences(words,summary)\n","      vid_table[vid_id]['transcription_transition_wordcount']=occurrences(words,transition)\n","      #https://py-readability-metrics.readthedocs.io/en/latest/\n","\n","      print('transcript features added.')\n","\n","    else:\n","      #print(e)\n","      print('speech annotation does not exist!')\n","      print(str(y['annotation_results'][0]['speech_transcriptions'][2]['alternatives'][0]))\n","      break"]},{"cell_type":"markdown","metadata":{"id":"TJ-L_252liHQ"},"source":["Transcript data from additional resources - speech2txt.py "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVSzAJUZiaST"},"outputs":[],"source":["file_names = os.listdir('text/transcript_text/unlabeled/raw_text/')\n","for f in file_names:\n","  if f[-3:]=='txt':\n","    vid_id=f[:-4]\n","    if vid_id not in vid_table.keys():\n","      vid_table[vid_id]={}\n","\n","    try:\n","      vid_table[vid_id]['transcript_wordcount'].split('')\n","    except:\n","      x=open('text/transcript_text/unlabeled/raw_text/%s'%f).readlines()\n","      if len(x)>0:\n","        corpus=x[0].lower()\n","        \n","        vid_table[vid_id]['transcript_sentence_count']=len(corpus.split('.'))\n","        corpuses_unlabeled[vid_id]=corpus\n","        try:\n","          results = readability.getmeasures(corpus, lang='en')\n","          vid_table[vid_id]['readability']= results['readability grades']['ARI']\n","        except:\n","          print('readability unavailable!')\n","        #word counts\n","        words=nltk.word_tokenize(corpus)\n","\n","        vid_table[vid_id]['transcript_wordcount']=len(words)\n","        vid_table[vid_id]['transcript_unique_wordcount']=len(set(words))  \n","\n","        vid_table[vid_id]['transcription_active_wordcount']=occurrences(tags_from_corpus(words),pos_tags)\n","        vid_table[vid_id]['transcription_summary_wordcount']=occurrences(words,summary)\n","        vid_table[vid_id]['transcription_transition_wordcount']=occurrences(words,transition)\n","\n","  if f[-4:]=='json':\n","    vid_id=f[:-5]\n","    try:\n","      vid_table[vid_id]['test']=0\n","    except:\n","      vid_table[vid_id]={}\n","    y=open('text/transcript_text/unlabeled/raw_text/%s'%f).read()\n","    x=json.loads(y)\n","    conf=[]\n","\n","    for i in range(len(x)):\n","      conf.append(x[i]['confidence'])\n","      \n","    vid_table[vid_id]['transcription_confidence_avg']=np.mean(conf)"]},{"cell_type":"code","source":["for c in list(corpuses_unlabeled.keys()):\n","  with open('text/transcript_text/unlabeled/raw_text/%s.txt'%c,'w') as f:\n","    f.write(corpuses_unlabeled[c])"],"metadata":{"id":"tgKGeg2D8vsA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43R0nm6ByZ2l"},"source":["**Detection**"]},{"cell_type":"markdown","metadata":{"id":"-56oQinei-ea"},"source":["for Xiao's videos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87NtqkK9jATh"},"outputs":[],"source":["for vid in outputLabeled:\n","  # get bucket data as blob\n","  \n","  vid_file=vid[14:-5]\n","  vid_id=vid[14:-9]\n","  try:\n","    labeled_vid_table[vid_id]['unique_obj_count']+=0\n","    labeled_vid_table[vid_id]['scene_count']+=0\n","  except:\n","    #object and shot detection\n","    try:\n","      blob = bucket.blob(vid)\n","      print('===========================================================\\nVideo: %s'%vid)\n","      #downloaded_blob = blob.download_as_string()\n","      #downloaded_blob = downloaded_blob.decode(\"utf-8\") \n","      # parse x:\n","      #y = json.loads(downloaded_blob)\n","      y1=open('Labeled GCP Output (Xiao)/'+vid_file+'.json')\n","      y=json.load(y1)\n","      #object \n","      try:\n","        atn1=y[vid_file][0]['object']['annotationResults'][0]['objectAnnotations']\n","      except:\n","        try:\n","          atn1=y[vid_file][0]['objects']['annotationResults'][0]['objectAnnotations']\n","        except:\n","          try:\n","            atn1=y['annotation_results'][0]['object_annotations']\n","          except:\n","            atn1=y['annotation_results'][1]['object_annotations']\n","      #scene- the lengths of the array is the # of scenes\n","      try:\n","        atn2=y[vid_file][0]['shots']\n","      except:\n","        try:\n","          atn2=y['annotation_results'][0]['shot_annotations']\n","        except:\n","          atn2=y['annotation_results'][1]['shot_annotations']\n","      \n","      #frequencies of word\n","      obj_screen_time={}\n","      #confidence score of that entity \n","      obj_conf=[]\n","\n","      for i in range(len(atn1)):\n","        if 'confidence' in atn1[i].keys() and 'entity' in atn1[i].keys() and 'description' in atn1[i]['entity'].keys():\n","          if atn1[i]['entity']['description'] not in obj_screen_time.keys():\n","            obj_screen_time[atn1[i]['entity']['description']]=1\n","          else:\n","            obj_screen_time[atn1[i]['entity']['description']]+=1\n","          obj_conf.append([atn1[i]['entity']['description'],atn1[i]['confidence']])\n","      \n","      conf_scores=np.array([c[1] for c in obj_conf])\n","\n","      labeled_vid_table[vid_id]['unique_obj_count']=len(obj_screen_time)\n","      labeled_vid_table[vid_id]['scene_count']=len(atn2)\n","\n","      #plt.hist(conf_scores,bins='auto')\n","      print('object and shot detection features added.')\n","\n","\n","    except:\n","      print('object or shot detection does not exist!')\n","      #print(str(y['annotation_results'][0].keys()))\n","      #try:\n","      #  print(str(y[vid_file]['annotation_results'])[:500])\n","      #except:\n","      #  break\n","\n","\n","      #break\n"]},{"cell_type":"markdown","metadata":{"id":"hSIChVy5i9JZ"},"source":["for our videos "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMBRKyp1h5JM"},"outputs":[],"source":["for vid in outputDetection:\n","  # get bucket data as blob\n","  \n","  vid_id=vid[16:-5]\n","  try:\n","    vid_table[vid_id]['unique_obj_count']+=0\n","    vid_table[vid_id]['scene_count']+=0\n","  except:\n","    #object and shot detection\n","    if vid_id not in vid_table.keys():\n","      vid_table[vid_id]={}\n","    try:\n","      blob = bucket.blob(vid)\n","      print('===========================================================\\nVideo: %s'%vid)\n","      downloaded_blob = blob.download_as_string()\n","      downloaded_blob = downloaded_blob.decode(\"utf-8\") \n","      # parse x:\n","      y = json.loads(downloaded_blob)\n","      #object \n","      atn1=y['annotation_results'][0]['object_annotations']\n","\n","      #scene- the lengths of the array is the # of scenes\n","      atn2=y['annotation_results'][0]['shot_annotations']\n","      \n","      #frequencies of word\n","      obj_screen_time={}\n","      #confidence score of that entity \n","      obj_conf=[]\n","\n","      for i in range(len(atn1)):\n","        if atn1[i]['entity']['description'] not in obj_screen_time.keys():\n","          obj_screen_time[atn1[i]['entity']['description']]=1\n","        else:\n","          obj_screen_time[atn1[i]['entity']['description']]+=1\n","        obj_conf.append([atn1[i]['entity']['description'],atn1[i]['confidence']])\n","      \n","      conf_scores=np.array([c[1] for c in obj_conf])\n","      if vid_id in vid_table.keys():\n","        vid_table[vid_id]['unique_obj_count']=len(obj_screen_time)\n","        vid_table[vid_id]['scene_count']=len(atn2)\n","      else:\n","        vid_table[vid_id]={}\n","        vid_table[vid_id]['unique_obj_count']=len(obj_screen_time)\n","        vid_table[vid_id]['scene_count']=len(atn2)   \n","\n","      #plt.hist(conf_scores,bins='auto')\n","      print('object and shot detection features added.')\n","\n","\n","    except:\n","      print('object or shot detection does not exist!')\n","      print(str(y['annotation_results'][0].keys())[:400])\n"]},{"cell_type":"markdown","metadata":{"id":"gqq2I2s7u5Ef"},"source":["**OCR**"]},{"cell_type":"markdown","metadata":{"id":"nxeUOMHPrCz7"},"source":["OCR for Xiao's video "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNck_XAJrCH9"},"outputs":[],"source":["for vid in outputLabeled:\n","  # get bucket data as blob\n","  \n","  #concatenate video ID\n","  vid_file=vid[14:-5]\n","  vid_id=vid[14:-9]\n","  try:\n","    labeled_vid_table[vid_id]['OCR_confidence_avg']+=0\n","  except:\n","    blob = bucket.blob(vid)\n","    print('===========================================================\\nVideo: %s'%vid)\n","    #downloaded_blob = blob.download_as_string()\n","    #downloaded_blob = downloaded_blob.decode(\"utf-8\") \n","    # parse x:\n","    #y = json.loads(downloaded_blob)\n","    y1=open('Labeled GCP Output (Xiao)/'+vid_file+'.json')\n","    y=json.load(y1)\n","    #OCR (visul texts) annotations\n","    try:\n","      try:\n","        atn3=y[vid_file][0]['text']['annotationResults'][0]['textAnnotations']\n","      except:\n","        try:\n","          atn3=y['annotation_results'][0]['text_annotations']\n","        except:\n","          try:\n","            atn3=y['annotation_results'][1]['text_annotations']\n","          except:\n","            atn3=y[vid_file][0]['text']\n","      #frequencies of word\n","      screen_time={}\n","      #confidence score of that entity \n","      conf=[]\n","      for i in range(len(atn3)):\n","        conf.append([atn3[i]['text'],atn3[i]['segments'][0]['confidence']])\n","\n","      #confidence scores\n","      conf_scores=np.array([c[1] for c in conf]) \n","\n","      #add confidence score as a feature to vid_table\n","      labeled_vid_table[vid_id]['OCR_confidence_avg']=np.mean(conf_scores)\n","\n","      #plt.hist(conf_scores,bins='auto')\n","      \n","      print('OCR text annotation features added.')\n","\n","    except:\n","      print('text annotation does not exist!')\n","      print(str(y.keys())[:400])\n","      #break\n"]},{"cell_type":"markdown","metadata":{"id":"24iF77LSo4ug"},"source":["OCR for our videos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8Vxmy02luUd"},"outputs":[],"source":["for vid in outputOCR:\n","  # get bucket data as blob\n","  \n","  #concatenate video ID\n","  vid_id=vid[10:-5]\n","\n","  try:\n","    vid_table[vid_id]['OCR_confidence_avg']+=0\n","    print(vid_table[vid_id]['OCR_confidence_avg'])\n","    print(vid_id)\n","  except:\n","    if vid_id not in vid_table.keys():\n","      vid_table[vid_id]={}\n","    blob = bucket.blob(vid)\n","    print('===========================================================\\nVideo: %s'%vid)\n","    downloaded_blob = blob.download_as_string()\n","    downloaded_blob = downloaded_blob.decode(\"utf-8\") \n","    # parse x:\n","    y = json.loads(downloaded_blob)\n","    #OCR (visul texts) annotations\n","    try:\n","      atn3=y['annotation_results'][0]['text_annotations']\n","      #frequencies of word\n","      screen_time={}\n","      #confidence score of that entity \n","      conf=[]\n","      for i in range(len(atn3)):\n","        if 'text' in atn3[i].keys() and 'segments' in atn3[i].keys():\n","          conf.append([atn3[i]['text'],atn3[i]['segments'][0]['confidence']])\n","\n","      #confidence scores\n","      conf_scores=np.array([c[1] for c in conf]) \n","\n","      #add confidence score as a feature to vid_table\n","      if vid_id in vid_table.keys():\n","        print('processed')\n","        vid_table[vid_id]['OCR_confidence_avg']=np.mean(conf_scores)\n","      else:\n","        vid_table[vid_id]={}\n","        vid_table[vid_id]['OCR_confidence_avg']=np.mean(conf_scores)\n","      \n","      print('OCR text annotation features added.')\n","\n","    except:\n","      print('text annotation does not exist!')\n","      print(y['annotation_results'][0]['segment'])\n","      \n"]},{"cell_type":"markdown","metadata":{"id":"yYJ8P-6M4fRR"},"source":["**transform map to pandas dataframe**"]},{"cell_type":"markdown","metadata":{"id":"FTDmuHQOt94F"},"source":["**Xiao's json files** "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ik53xgNWtuNa"},"outputs":[],"source":["cols=labeled_vid_table['-71ld0iqAq8'].keys()\n","idx=labeled_vid_table.keys()\n","labeled_vid_table_pd=pd.DataFrame(columns=cols,index=idx)\n","\n","for i,id in enumerate(idx):\n","  for col in cols:\n","    if col in labeled_vid_table[id].keys():\n","      labeled_vid_table_pd.iloc[i][col]=labeled_vid_table[id][col]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQEtUwjXuK31"},"outputs":[],"source":["labeled_vid_table_pd=labeled_vid_table_pd.reset_index()\n","#\n","#json file \n","labeled_vid_table_pd=labeled_vid_table_pd.rename(columns={'index':'video_ID'})\n","labeled_vid_table_pd=labeled_vid_table_pd.set_index('video_ID')\n","#labeled_vid_table_pd=labeled_vid_table_pd.drop(columns='test')\n","labeled_vid_table_pd"]},{"cell_type":"code","source":["labeled_vid_table_pd.to_csv('Content Features Table (Labeled data - Xiao)/labeled_video_raw_content.csv')"],"metadata":{"id":"Ef_ezVyBYBZA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a6ooBqFCuAiy"},"source":["**features of our video**"]},{"cell_type":"code","source":["print(vid_table['z4Om-v-ZhLI']['OCR_confidence_avg'])"],"metadata":{"id":"5hE-LYHtbjo5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa9c-arzaVpQ"},"outputs":[],"source":["cols=vid_table['-iL5AeXjpgg'].keys()\n","idx=vid_table.keys()\n","vid_table_pd=pd.DataFrame(columns=cols,index=idx)\n","print(len(vid_table))\n","\n","for i,id in enumerate(idx):\n","  #filter out the duplicates in LabeledIDs\n","  if id in detectionIDs and i not in labeledIDs:\n","    for col in cols:\n","      if col in vid_table[id].keys():\n","        vid_table_pd.iloc[i][col]=vid_table[id][col]"]},{"cell_type":"code","source":["print(cols)"],"metadata":{"id":"PDd3GLSxXwrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3u772GHq4Clz"},"outputs":[],"source":["vid_table_pd=vid_table_pd.reset_index()\n","#json file \n","vid_table_pd=vid_table_pd.rename(columns={'index':'video_ID'})\n","vid_table_pd=vid_table_pd.set_index('video_ID')\n","#vid_table_pd=vid_table_pd.drop(columns='test')\n","#vid_table_pd.dropna()"]},{"cell_type":"code","source":["vid_table_pd"],"metadata":{"id":"UHsU-TFsOo0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vid_table_pd.to_csv('Content Features Table (Unlabeled data) /video_raw_content.csv')"],"metadata":{"id":"iIyjcVfXfba1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"content_feature_json_to_csv.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}